<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>CARLA Sensors - 交通仿真文档</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../../extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "CARLA Sensors";
        var mkdocs_page_input_path = "algorithms\\Sensors\\_CARLA.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> 交通仿真文档
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../..">主页</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">交通仿真文档</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">CARLA Sensors</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/OpenHUTB/carla_doc/edit/master/docs/algorithms/Sensors/_CARLA.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="sensors-in-carla">Sensors in CARLA<a name="Sensor"></a></h1>
<p>Sensors in CARLA compound a specific family of actors that are quite diverse and unique from the other CARLA actors; they model different sensing capabilities that can be used in self-driving systems. 
Sensors are represented by CARLA actors that are normally spawned as attachment/sons of a vehicle. 
Sensors are thoroughly designed to retrieve different types of data that they are listening to. </p>
<p>Most sensors can be divided in two groups: those receiving data on every tick (cameras, point clouds and some other specific sensors) and those who only receive under certain circumstances (trigger detectors). CARLA provides a specific set of sensors and their blueprint can be found in <a href="#carla.BlueprintLibrary">carla.BlueprintLibrary</a>. </p>
<h3 id="instance-variables">Instance Variables</h3>
<ul>
<li><a name="carla.Sensor.is_listening"></a><strong><font color="#f8805a">is_listening</font></strong> (<em>boolean</em>)<br />
When <b>True</b> the sensor will be waiting for data.  </li>
</ul>
<h3 id="methods">Methods</h3>
<ul>
<li><a name="carla.Sensor.listen"></a><strong><font color="#7fb800">listen</font></strong>(<font color="#00a6ed"><strong>self</strong></font>, <font color="#00a6ed"><strong>callback</strong></font>)<button class="SnipetButton" id="carla.Sensor.listen-snipet_button">snippet &rarr;</button><br />
The function the sensor will be calling to every time a new measurement is received. This function needs for an argument containing an object type <a href="#carla.SensorData">carla.SensorData</a> to work with.  <ul>
<li><strong>Parameters:</strong><ul>
<li><code>callback</code> (<em>function</em>) - The called function with one argument containing the sensor data.  </li>
</ul>
</li>
</ul>
</li>
<li><a name="carla.Sensor.stop"></a><strong><font color="#7fb800">stop</font></strong>(<font color="#00a6ed"><strong>self</strong></font>)<br />
Commands the sensor to stop listening for data.  </li>
</ul>
<h2 id="carlacamera">CarlaCamera</h2>
<p>The "RGB" camera acts as a regular <a href="index.html#Camera">camera</a> capturing images from the scene.
A CARLA camera can be tuned with respect to multiple parameters, such as <code>sensor_tick</code> and <code>enable_postprocess_effects</code>. 
The numeric <code>sensor_tick</code> parameter controls how fast we want the sensor to capture the scene: 
for example, a value of 1.5 means that we want the sensor to capture an image each second and a half. The value 0.0 is used as default and it instructs the camera to capture images as fast as possible.</p>
<p>The <code>enable_postprocess_effects</code> parameters allows the user to increase the realism of the captured images, by applying the corresponding set of post-process effects:</p>
<ul>
<li><strong>Vignette:</strong> darkens the border of the screen.</li>
<li><strong>Grain jitter:</strong> adds some noise to the render.</li>
<li><strong>Bloom:</strong> intense lights burn the area around them.</li>
<li><strong>Auto exposure:</strong> modifies the image gamma to simulate the eye adaptation to darker or brighter areas.</li>
<li><strong>Lens flares:</strong> simulates the reflection of bright objects on the lens.</li>
<li><strong>Depth of field:</strong> blurs objects near or very far away from the camera.</li>
</ul>
<h2 id="carlalidar">CarlaLiDAR</h2>
<p>This sensor simulates a rotating <a href="index.html#LiDAR">LiDAR</a> implemented using ray-casting.
The points are computed by adding a laser beam for each channel distributed in the vertical FOV. 
The rotation is simulated by computing the horizontal angle corresponding to how much the LiDAR rotated between two consecutive frames taken with frequency <code>FPS</code>, that is, the LiDAR rotation angle in <code>1/FPS</code> seconds. 
The point cloud is calculated by doing a ray-cast for each laser beam in every step.
<code>points_per_channel_each_step = points_per_second / (FPS * channels)</code></p>
<p>A LIDAR measurement contains a package with all the points generated during an interval of length <code>1/FPS</code>. 
During this interval the physics of the world are not updated so all points in the measurement reflect the same "static picture" of the scene.</p>
<p>This output contains a cloud of simulation points and thus, it can be iterated to retrieve a list of their <a href="python_api.md#carla.Location"><code>carla.Location</code></a>:</p>
<pre><code class="language-py">for location in lidar_measurement:
    print(location)
</code></pre>
<p>The information of the LiDAR measurement is encoded by means of 4D points. 
The first three dimensions represent the space points in the usual XYZ spatial coordinates; 
the last one stands for the intensity loss during the travel. 
This intensity is computed by the following formula.
<br></p>
<p><code>a</code> — Attenuation coefficient. This may depend on the sensor's wavelength, and the conditions of the atmosphere. It can be modified with the LiDAR attribute <code>atmosphere_attenuation_rate</code>.
<code>d</code> — Distance from the hit point to the sensor.</p>
<p>For a better realism, points in the cloud can be dropped off. This is an easy way to simulate loss due to external perturbations. This can done combining two different parameters.</p>
<ul>
<li><strong>General drop-off</strong> — Proportion of points that are dropped off randomly. This is done before the tracing, meaning the points being dropped are not calculated, thus improving the performance. If <code>dropoff_general_rate = 0.5</code>, half of the points will be dropped.</li>
<li><strong>Intensity-based drop-off</strong> — For each point detected, and extra drop-off is performed with a probability based in the computed intensity. This probability is determined by two parameters: <code>dropoff_zero_intensity</code> and <code>dropoff_intensity_limit</code>, where is the probability of points with zero intensity to be dropped while <code>dropoff_intensity_limit</code> is a threshold intensity above which no points will be dropped. The probability of a point within the range to be dropped is a linear proportion based on these two parameters.</li>
</ul>
<p>Additionally, the <code>noise_stddev</code> attribute makes for a noise model to simulate unexpected deviations that appear in real-life sensors. For positive values, each point is randomly perturbed along the vector of the laser beam. The result is a LiDAR sensor with perfect angular positioning, but noisy distance measurement.</p>
<p>The rotation of the LiDAR can be tuned to cover a specific angle on every simulation step (using a <a href="adv_synchrony_timestep.md">fixed time-step</a>). For example, to rotate once per step (full circle output, as in the picture below), the rotation frequency and the simulated FPS should be the same; 
this can be obtained by <br><strong>1.</strong> Setting the sensor's rotation_frequency attribute <code>sensors_bp['lidar'][0].set_attribute('rotation_frequency','10')</code>. <br> <strong>2.</strong> Running the simulation using the option <code>--fps=N</code>, e.g., <code>python3 config.py --fps=10</code>.</p>
<h2 id="carlagnss">CarlaGNSS</h2>
<ul>
<li><strong>Blueprint:</strong> sensor.other.gnss</li>
<li><strong>Output:</strong> <a href="python_api.md#carla.GnssMeasurement">carla.GNSSMeasurement</a> per step (unless <code>sensor_tick</code> says otherwise).</li>
</ul>
<p>This sensors models a <a href="index.html#GPS_IMU">GPS receiver</a> and it provides the current <a href="https://www.gsa.europa.eu/european-gnss/what-gnss">GNSS position</a> of the vehicle the sensor is attached to. 
The current coordinates are calculated by adding the metric position to an initial geo reference location defined within the OpenDRIVE map definition.</p>
<h4 id="gnss-attributes">GNSS attributes</h4>
<table>
<thead>
<tr>
<th>Blueprint attribute</th>
<th>Type</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>noise_alt_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>Mean parameter in the noise model for altitude.</td>
</tr>
<tr>
<td><code>noise_alt_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>Standard deviation parameter in the noise model for altitude.</td>
</tr>
<tr>
<td><code>noise_lat_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>Mean parameter in the noise model for latitude.</td>
</tr>
<tr>
<td><code>noise_lat_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>Standard deviation parameter in the noise model for latitude.</td>
</tr>
<tr>
<td><code>noise_lon_bias</code></td>
<td>float</td>
<td>0.0</td>
<td>Mean parameter in the noise model for longitude.</td>
</tr>
<tr>
<td><code>noise_lon_stddev</code></td>
<td>float</td>
<td>0.0</td>
<td>Standard deviation parameter in the noise model for longitude.</td>
</tr>
<tr>
<td><code>noise_seed</code></td>
<td>int</td>
<td>0</td>
<td>Initializer for a pseudorandom number generator.</td>
</tr>
<tr>
<td><code>sensor_tick</code></td>
<td>float</td>
<td>0.0</td>
<td>Simulation seconds between sensor captures (ticks).</td>
</tr>
</tbody>
</table>
<p><br></p>
<h4 id="output-attributes">Output attributes</h4>
<table>
<thead>
<tr>
<th>Sensor data attribute</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>frame</code></td>
<td>int</td>
<td>Frame number when the measurement took place.</td>
</tr>
<tr>
<td><code>timestamp</code></td>
<td>double</td>
<td>Simulation time of the measurement in seconds since the beginning of the episode.</td>
</tr>
<tr>
<td><code>transform</code></td>
<td><a href="../python_api#carlatransform">carla.Transform</a></td>
<td>Location and rotation in world coordinates of the sensor at the time of the measurement.</td>
</tr>
<tr>
<td><code>latitude</code></td>
<td>double</td>
<td>Latitude of the actor.</td>
</tr>
<tr>
<td><code>longitude</code></td>
<td>double</td>
<td>Longitude of the actor.</td>
</tr>
<tr>
<td><code>altitude</code></td>
<td>double</td>
<td>Altitude of the actor.</td>
</tr>
</tbody>
</table>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/OpenHUTB/carla_doc" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../extra.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
