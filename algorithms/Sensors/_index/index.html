<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../../img/favicon.ico" />
    <title>Sensors - 交通仿真文档</title>
    <link rel="stylesheet" href="../../../css/theme.css" />
    <link rel="stylesheet" href="../../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../../extra.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Sensors";
        var mkdocs_page_input_path = "algorithms\\Sensors\\_index.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../../.." class="icon icon-home"> 交通仿真文档
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../..">首页</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../..">交通仿真文档</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../.." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Sensors</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/OpenHUTB/carla_doc/edit/master/docs/algorithms/Sensors/_index.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="sensors-in-self-driving-systems">Sensors in Self-driving Systems</h1>
<p>Sensor classes based on the data source, such as simulators like CARLA and BeamNG and real vehicles, play a pivotal role in the development and testing of autonomous driving systems. These sensors serve as the eyes and ears of self-driving vehicles, providing crucial data for navigation, perception, and decision-making algorithms. In this context, sensor simulation becomes a critical component of the development process, allowing engineers to assess the system's performance in a controlled environment before deploying it in the real world.</p>
<p>Simulators like CARLA and BeamNG are powerful tools for sensor simulation, offering a range of sensor classes that mimic the behavior of real-world sensors. These simulators generate synthetic data, replicating the sensory input that an autonomous vehicle would receive while driving. The sensors commonly simulated in these environments include:</p>
<ol>
<li>
<p><strong>LiDAR (Light Detection and Ranging)</strong><a name="LiDAR"/>: Simulated LiDAR sensors emit laser beams and measure their reflection from surrounding objects, providing detailed 3D point clouds. These simulators replicate the physics of LiDAR, including beam divergence and range accuracy, allowing developers to evaluate their algorithms' performance in various scenarios.
<img alt="carla_lidar_point_cloud" src="../../assets/sensors/carla_lidar_point_cloud.jpg" />{: .center-image width="480"}</p>
</li>
<li>
<p><strong>Radar</strong><a name="Radar"/>: Radar sensors use radio waves to detect objects and their relative speed. Simulated radar sensors emulate the radar signal's propagation and reflection, including effects like interference and attenuation, to generate realistic sensor data.
<img alt="carla_sensors_radar" src="../../assets/sensors/carla_sensors_radar.jpg" />{: .center-image width="480"}</p>
</li>
<li>
<p><strong>Camera</strong><a name="Camera"/>: Simulated cameras replicate the behavior of vision sensors, including factors such as lens distortion, exposure, and image noise. These simulations enable the testing of computer vision algorithms for tasks like object detection, lane tracking, and traffic sign recognition.
<img alt="carla_sensors_rgb" src="../../assets/sensors/carla_sensors_rgb.jpg" />{: .center-image width="480"}</p>
</li>
<li>
<p><strong>GPS and IMU (Inertial Measurement Unit)<a name="GPS_IMU"/></strong>: Simulated GPS and IMU sensors provide vehicle localization and orientation data. These sensors simulate satellite signals and vehicle movements, allowing developers to assess GPS-based localization and sensor fusion algorithms.</p>
</li>
<li>
<p><strong>Ultrasonic Sensors<a name="Ultrasonic"/></strong>: Simulated ultrasonic sensors model the way ultrasonic waves bounce off objects to measure distances. They are crucial for detecting nearby obstacles during parking and low-speed maneuvers.</p>
</li>
<li>
<p><strong>Wheel Odometry<a name="Odometry"/></strong>: Simulated wheel odometry sensors estimate the vehicle's motion based on wheel rotations. These sensors aid in dead reckoning and can be used for localization when GPS signals are weak or unavailable.</p>
</li>
</ol>
<p>Data generated by these simulated sensors is typically provided in formats that mimic real-world sensor outputs, such as point clouds for LiDAR, radar sweeps for radar, and image frames for cameras. Developers can configure the sensor properties and environmental conditions within the simulators to create diverse testing scenarios, including different weather conditions, traffic patterns, and road types.</p>
<p>In summary, sensor simulation in autonomous driving development, whether its data is produced by simulators like CARLA and BeamNG or collected by using real vehicles, is indispensable for verifying and fine-tuning perception and control algorithms. It allows developers to evaluate the robustness and reliability of these systems under various conditions, ultimately contributing to the safe deployment of autonomous vehicles on our roads.</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/OpenHUTB/carla_doc" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
    
  </span>
</div>
    <script src="../../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../../..";</script>
    <script src="../../../js/theme_extra.js"></script>
    <script src="../../../js/theme.js"></script>
      <script src="../../../extra.js"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script src="../../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
